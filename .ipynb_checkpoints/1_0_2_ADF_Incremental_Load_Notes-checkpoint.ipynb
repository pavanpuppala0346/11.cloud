{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c4ed311",
   "metadata": {},
   "source": [
    "# Azure Data Factory - Incremental Data Load\n",
    "This notebook explains how to implement an **Incremental Data Load** in Azure Data Factory (ADF) using a practical pipeline example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0add7dca",
   "metadata": {},
   "source": [
    "## üìå Business Requirement\n",
    "- Data is stored in a SQL DB `orders` table.\n",
    "- We need to copy data to a `orders_final` table **incrementally**.\n",
    "- Only a subset of columns should be copied (e.g., exclude `last_name`).\n",
    "- On re-run, only new records (based on `insert_time`) should be copied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c777b99",
   "metadata": {},
   "source": [
    "## üîÑ What is Incremental Load?\n",
    "- Rather than loading full data every time, we copy **only new records**.\n",
    "- Helps reduce data load, improves efficiency and performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f016fe",
   "metadata": {},
   "source": [
    "## üß† Strategy\n",
    "1. Extract the maximum `insert_time` from the **sink** table (`orders_final`).\n",
    "2. In the next load, query only records from the **source** table (`orders`) with `insert_time > max_insert_time`.\n",
    "3. Copy only relevant columns to the final table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e59e89",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è ADF Pipeline Steps\n",
    "1. **Lookup Activity**: Get the latest `insert_time` from `orders_final` table.\n",
    "   ```sql\n",
    "   SELECT MAX(insert_time) AS date1 FROM orders_final\n",
    "   ```\n",
    "2. **Copy Activity**:\n",
    "   - Source: SQL table `orders`\n",
    "   - Query:\n",
    "   ```sql\n",
    "   SELECT order_id, name, insert_time\n",
    "   FROM orders\n",
    "   WHERE insert_time > '@{activity('Lookup1').output.firstRow.date1}'\n",
    "   ```\n",
    "   - Sink: SQL table `orders_final`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5a2c78",
   "metadata": {},
   "source": [
    "## ‚úÖ Sample Tables\n",
    "### Source: `orders`\n",
    "| order_id | name     | last_name | insert_time          |\n",
    "|----------|----------|-----------|----------------------|\n",
    "| 1        | Alice    | Smith     | 2025-07-25 09:10:00  |\n",
    "| 2        | Bob      | Johnson   | 2025-07-25 09:15:00  |\n",
    "| 3        | Charlie  | Brown     | 2025-07-25 09:20:00  |\n",
    "| 4        | Diana    | Prince    | 2025-07-26 10:00:00  |\n",
    "\n",
    "### Sink: `orders_final`\n",
    "| order_id | name     | insert_time          |\n",
    "|----------|----------|----------------------|\n",
    "| 1        | Alice    | 2025-07-25 09:10:00  |\n",
    "| 2        | Bob      | 2025-07-25 09:15:00  |\n",
    "| 3        | Charlie  | 2025-07-25 09:20:00  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51b3a06",
   "metadata": {},
   "source": [
    "## üîÅ Run and Verify\n",
    "- Insert new record in `orders` table.\n",
    "- Run the pipeline again.\n",
    "- Verify that only new records are inserted into `orders_final`.\n",
    "- Example:\n",
    "```sql\n",
    "INSERT INTO orders VALUES (5, 'Eve', 'Evans', '2025-07-28 17:00:00');\n",
    "```\n",
    "Expected: Only record with order_id=5 should be inserted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ae5c64",
   "metadata": {},
   "source": [
    "## üìù Notes\n",
    "- Always use a reliable timestamp (`insert_time`) for incremental logic.\n",
    "- Make sure timezone and format consistency is maintained.\n",
    "- Consider watermark tables for production-grade pipelines."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}